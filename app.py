# -*- coding: utf-8 -*-
import os
import sys
import json
import aiofiles
import importlib
import threading
from pyxxl import error
from aiohttp import web
from time import sleep, time
from datetime import datetime
from pyxxl.logger import LogBase
from pyxxl.schema import RunData
from threading import Lock, Timer
from urllib.parse import parse_qs
from pyxxl.types import LogRequest
from pyxxl.executor import Executor
from pyxxl.logger.disk import DiskLog
from typing import Optional, TypedDict
from watchdog.observers import Observer
from log_utils import logger, get_log_file
from pyxxl.server import routes, app_logger
from pyxxl import ExecutorConfig, PyxxlRunner
from watchdog.events import FileSystemEventHandler

_original_run_job = Executor.run_job

jobs_path = "jobs"

# ç§»é™¤åŸæ¥çš„ /log
routes._items = [
    r for r in routes._items
    if not (r.method == "POST" and r.path == "/log")
]


# é‡æ–°æ³¨å†Œä¸€ä¸ªç¬¦åˆ XXL-Job Java Admin è§£æè§„åˆ™çš„ /log
@routes.post("/log")
async def log(request: web.Request) -> web.Response:
    """
        {
        "logDateTim":0,     // æœ¬æ¬¡è°ƒåº¦æ—¥å¿—æ—¶é—´
        "logId":0,          // æœ¬æ¬¡è°ƒåº¦æ—¥å¿—ID
        "fromLineNum":0     // æ—¥å¿—å¼€å§‹è¡Œå·ï¼Œæ»šåŠ¨åŠ è½½æ—¥å¿—
    }
    """
    data = await request.json()
    app_logger(request).debug("get log request %s" % data)
    task_log: LogBase = request.app["pyxxl_state"].task_log

    return web.json_response({
        "code": 200,
        "msg": "æ—¥å¿—è·å–æˆåŠŸ",  # ğŸš¨ å…³é”®ï¼šä¸èƒ½æ˜¯ Noneï¼Œå¿…é¡»æ˜¯ ""
        "data": await task_log.get_logs(data),
    })


@routes.get("/healthCheck")
async def health_check(request: web.Request) -> web.Response:
    return web.json_response({"code": 200, "msg": "å½“å‰ç³»ç»ŸçŠ¶æ€è‰¯å¥½", "data": None})


class LogResponse(TypedDict):
    fromLineNum: int
    toLineNum: int
    logContent: str
    isEnd: bool


async def hacked_get_logs(self, request: LogRequest, *, key: Optional[str] = None) -> LogResponse:
    # todo: ä¼˜åŒ–è·å–ä¸­é—´è¡Œçš„é€»è¾‘ï¼Œç¼“å­˜ä¹‹å‰æ¯è¡Œæ—¥å¿—çš„å¤§å°ç„¶åç›´æ¥seek
    key = key or self.key(request["logId"])
    logs = ""
    from_line = request["fromLineNum"]
    to_line_num = from_line - 1  # ğŸ‘ˆ åˆå§‹åŒ–ä¸ºä¸Šä¸€è¡Œ
    is_end = False

    try:
        async with aiofiles.open(key, mode="r") as f:
            # è¯»å–ä»ç¬¬ 1 è¡Œåˆ° (from_line + tail - 1) è¡Œ
            for i in range(1, from_line + self.log_tail_lines):
                line = await f.readline()
                if line == "":
                    is_end = True
                    break
                if i >= from_line:
                    to_line_num = i
                    logs += line
    except FileNotFoundError as e:
        self.executor_logger.warning(str(e), exc_info=True)
        logs = "No such logid logs."
        is_end = True  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿç®—â€œç»“æŸâ€
    return LogResponse(
        fromLineNum=request["fromLineNum"],
        toLineNum=to_line_num,
        logContent=logs,
        isEnd=is_end,
    )


DiskLog.get_logs = hacked_get_logs


def _get_mode(data: RunData):
    """
    ä» executorParams ä¸­è§£æ mode
    æ”¯æŒ:
      mode=discard
      mode=serial
      {"mode":"discard"}   # å¦‚æœä½ ç”¨çš„æ˜¯ JSON
    """
    params = data.executorParams or ""

    # JSON é£æ ¼
    if params.startswith("{") and params.endswith("}"):
        try:
            return json.loads(params).get("mode")
        except (Exception,):
            return None

    # querystring é£æ ¼
    qs = parse_qs(params)
    return qs.get("mode", [None])[0]


async def hacked_run_job(self, data: RunData):
    handler_obj = self.handler.get(data.executorHandler)
    if not handler_obj:
        self.executor_logger.warning("handler %s not found." % data.executorHandler)
        raise error.JobNotFoundError("handler %s not found." % data.executorHandler)

    mode = _get_mode(data)
    force_discard = (mode == "discard")

    async with self.lock:
        current_task = self.tasks.get(data.jobId)
        queue = self.get_queue(data.jobId)

        # æ²¡æœ‰åœ¨è·‘ â†’ ç›´æ¥æ‰§è¡Œ
        if not current_task and queue.empty():
            self.tasks[data.jobId] = self._create_task(data)
            return "Running"

        self.executor_logger.warning(
            "jobId=%s handler=%s mode=%s running, strategy=%s",
            data.jobId,
            data.executorHandler,
            mode,
            data.executorBlockStrategy,
        )

        # ğŸ’£ Executor çº§ä¸¢å¼ƒï¼ˆAdmin ä»¥ä¸ºæ˜¯ SERIALï¼‰
        if force_discard:
            self.executor_logger.warning(
                f"[DISCARD_BY_PARAM] jobId={data.jobId} "
                f"handler={data.executorHandler} "
                f"logId={data.logId} params={data.executorParams}"
            )

            # ğŸ’¡ å…³é”®ï¼šåˆ›å»ºç©ºæ—¥å¿—æ–‡ä»¶
            log_file_path = os.path.join(
                self.config.log_local_dir,
                f"pyxxl-{data.logId}.log"
            )
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(log_file_path), exist_ok=True)

            # ç”Ÿæˆæ—¥å¿—å†…å®¹
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            log_content = (
                f"[{timestamp}] INFO - Task discarded by executor.\n"
                f"[{timestamp}] INFO - Reason: Execution mode is 'discard'.\n"
                f"[{timestamp}] INFO - Job ID: {data.jobId}, Log ID: {data.logId}\n"
                f"[{timestamp}] INFO - Handler: {data.executorHandler}\n"
                f"[{timestamp}] INFO - Parameters: {data.executorParams}\n"
            )

            # åˆ›å»ºç©ºæ–‡ä»¶ï¼ˆå¼‚æ­¥ï¼‰
            async with aiofiles.open(log_file_path, "w") as f:
                await f.write(log_content)

            start_time = int(time() * 1000)
            # è¿”å› 200 ç»™ admin
            await self.xxl_client.callback(
                data.logId,
                start_time,
                code=200,  # 200 = Admin æ˜¾ç¤ºâ€œæ‰§è¡ŒæˆåŠŸâ€
                # msg=msg,  # ğŸ‘ˆ è¿™ä¸ªä¼šæ˜¾ç¤ºåœ¨ã€Œæ‰§è¡Œå¤‡æ³¨ã€
                msg=""  # æ‰§è¡Œå¤‡æ³¨å°†ä»€ä¹ˆéƒ½ä¸æ˜¾ç¤ºã€‚ä¸è¦ä¼  Noneï¼Œä¸€å®šè¦æ˜¯ ""ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰ï¼Œå¦åˆ™ XXL-Job Java ç«¯å¯èƒ½ä¼šå†™æˆ "null"ã€‚
            )

            return "DISCARDED"

        # å¦åˆ™ï¼šèµ° XXL åŸå§‹ SERIAL / COVER / DISCARD é€»è¾‘
        return await _original_run_job(self, data)


# ğŸ”¥ æ‰“è¡¥ä¸
Executor.run_job = hacked_run_job

# ---------------------------------------------------
# 1. é…ç½® Pyxxl æ‰§è¡Œå™¨ï¼ˆå®˜æ–¹è§„èŒƒï¼‰
# ---------------------------------------------------
config = ExecutorConfig(
    xxl_admin_baseurl=os.getenv("XXL_JOB_ADMIN_ADDRESS", "http://192.168.3.240:18070/xxl-job-admin/api/"),
    executor_app_name=os.getenv("XXL_JOB_EXECUTOR_APPNAME", "playwright-cronjob-executor-1717"),

    # å®˜æ–¹æ¨èå­—æ®µåç§°
    executor_listen_host="0.0.0.0",
    executor_listen_port=int(os.getenv("XXL_JOB_EXECUTOR_PORT", 9996)),

    # è¿™é‡ŒæŒ‡å®š Admin å¯è®¿é—®çš„åœ°å€ï¼ˆå¿…é¡»æ˜¯çœŸå® IP + ç«¯å£ æˆ–åŸŸåï¼‰
    executor_url=os.getenv("XXL_JOB_EXECUTOR_URL", "http://192.168.3.240:9996/"),
    # æ‰§è¡Œå™¨ç»‘å®šçš„httpæœåŠ¡çš„url,xxl-adminé€šè¿‡è¿™ä¸ªhostæ¥å›è°ƒpyxxlæ‰§è¡Œå™¨.
    # Default: "http://{executor_listen_host}:{executor_listen_port}"

    access_token=os.getenv("XXL_JOB_ACCESS_TOKEN", "Abc123456"),
    executor_log_path=get_log_file(file_name="pyxxl.log"),

    # å»ºè®®å¼€å¯ debugï¼Œä¾¿äºå®šä½æ³¨å†ŒæˆåŠŸä¸å¦
    debug=True,
)

executor = PyxxlRunner(config)


# ---------------------------------------------------
# 2. é€šç”¨åŠ è½½ä»»åŠ¡å‡½æ•°
# ---------------------------------------------------
def load_job_module(module_path):
    """é€šç”¨åŠ è½½ä»»åŠ¡æ¨¡å—å¹¶æ³¨å†Œçš„å‡½æ•°"""
    try:
        module_name = module_path.split('.')[-1]

        # æŸ¥çœ‹ JobHandler ç±»çš„å±æ€§
        job_handler = executor.handler
        # æ­¥éª¤1ï¼šå–æ¶ˆæ³¨å†Œæ—§ä»»åŠ¡
        if hasattr(job_handler, '_handlers'):
            handlers_dict = job_handler._handlers

            if isinstance(handlers_dict, dict):
                logger.info(f"[pyxxl] å½“å‰æ³¨å†Œçš„ä»»åŠ¡æ•°é‡: {len(handlers_dict)}")

                if module_name in handlers_dict:
                    # ä¿å­˜æ—§å¤„ç†å™¨ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    old_handler = handlers_dict[module_name]
                    logger.info(f"[pyxxl] æ—§å¤„ç†å™¨ä¿¡æ¯: {type(old_handler)}")

                    # å–æ¶ˆæ³¨å†Œ
                    del handlers_dict[module_name]
                    logger.info(f"[pyxxl] âœ“ å·²å–æ¶ˆæ³¨å†Œä»»åŠ¡: {module_name}")

                    # éªŒè¯å–æ¶ˆæ³¨å†Œ
                    if module_name not in handlers_dict:
                        logger.info(f"[pyxxl] âœ“ å–æ¶ˆæ³¨å†ŒéªŒè¯æˆåŠŸ")
                    else:
                        logger.error(f"[pyxxl] âœ— å–æ¶ˆæ³¨å†ŒéªŒè¯å¤±è´¥")
                else:
                    logger.info(f"[pyxxl] ä»»åŠ¡ {module_name} æœªæ³¨å†Œï¼Œç›´æ¥è¿›è¡Œæ–°æ³¨å†Œ")
            else:
                logger.warning(f"[pyxxl] _handlers ä¸æ˜¯å­—å…¸: {type(handlers_dict)}")
        else:
            logger.warning(f"[pyxxl] æ— æ³•æ‰¾åˆ°ä»»åŠ¡å­—å…¸ï¼Œè·³è¿‡å–æ¶ˆæ³¨å†Œæ­¥éª¤")

        # æ­¥éª¤2ï¼šå¸è½½æ¨¡å—
        if module_path in sys.modules:
            # åœ¨å¸è½½å‰å°è¯•æ¸…ç†æ¨¡å—çŠ¶æ€
            old_module = sys.modules[module_path]

            # æ¸…ç†å¯èƒ½çš„æ¨¡å—çº§çŠ¶æ€
            if hasattr(old_module, '__pyxxl_cleanup__'):
                try:
                    old_module.__pyxxl_cleanup__()
                    logger.info(f"[pyxxl] æ‰§è¡Œæ¨¡å—æ¸…ç†å‡½æ•°")
                except Exception as e:
                    logger.warning(f"[pyxxl] æ¨¡å—æ¸…ç†å¤±è´¥: {e}")

            del sys.modules[module_path]
            logger.info(f"[pyxxl] âœ“ å·²å¸è½½æ¨¡å—: {module_path}")

        # æ­¥éª¤3ï¼šæ¸…é™¤å¯¼å…¥ç¼“å­˜
        importlib.invalidate_caches()
        logger.info(f"å·²æ¸…é™¤å¯¼å…¥ç¼“å­˜")

        # æ­¥éª¤4ï¼šé‡æ–°å¯¼å…¥æ¨¡å—
        logger.info(f"é‡æ–°å¯¼å…¥æ¨¡å—: {module_path}")
        module = importlib.import_module(module_path)

        # æ­¥éª¤5ï¼šé‡æ–°æ³¨å†Œä»»åŠ¡
        if hasattr(module, "register"):
            # æ£€æŸ¥æ³¨å†Œå‡½æ•°æ˜¯å¦å¯è°ƒç”¨
            if callable(module.register):
                module.register(executor)
                logger.info(f"[pyxxl] âœ“ æˆåŠŸè°ƒç”¨ register å‡½æ•°")

                # æ­¥éª¤6ï¼šéªŒè¯æ³¨å†Œç»“æœ
                if hasattr(job_handler, '_handlers') and isinstance(job_handler._handlers, dict):
                    if module_name in job_handler._handlers:
                        new_handler = job_handler._handlers[module_name]
                        logger.info(f"[pyxxl] âœ“ ä»»åŠ¡æ³¨å†ŒæˆåŠŸï¼Œæ–°å¤„ç†å™¨: {type(new_handler)}")
                    else:
                        logger.error(f"[pyxxl] âœ— ä»»åŠ¡æ³¨å†Œå¤±è´¥ï¼Œä»»åŠ¡æœªå‡ºç°åœ¨å¤„ç†å™¨å­—å…¸ä¸­")
                else:
                    logger.warning(f"[pyxxl] æ— æ³•éªŒè¯æ³¨å†Œç»“æœ")
            else:
                logger.error(f"register å±æ€§ä¸å¯è°ƒç”¨: {type(module.register)}")
        else:
            logger.warning(f"{module_path} æœªå®šä¹‰ register(executor)ï¼Œè·³è¿‡")

    except Exception as e:
        logger.error(f"ä»»åŠ¡<{module_path}>æ³¨å†Œå¤±è´¥ï¼ŒåŸå› : {e}")


def inspect_pyxxl_structure():
    """æŸ¥çœ‹ PyXXL æ‰§è¡Œå™¨çš„å®é™…ç»“æ„"""
    logger.info("=== PyXXL æ‰§è¡Œå™¨ç»“æ„åˆ†æ ===")

    # æŸ¥çœ‹æ‰§è¡Œå™¨ç±»çš„å±æ€§
    import pyxxl
    executor_class = pyxxl.executor.Executor
    class_attrs = [attr for attr in dir(executor_class) if not attr.startswith('__')]
    logger.info(f"Executorç±»å±æ€§: {class_attrs}")

    # æŸ¥çœ‹å®ä¾‹å±æ€§
    instance_attrs = [attr for attr in dir(executor) if not attr.startswith('_')]
    logger.info(f"æ‰§è¡Œå™¨å®ä¾‹å±æ€§: {instance_attrs}")

    # ç‰¹åˆ«æŸ¥çœ‹å­—å…¸ç±»å‹çš„å±æ€§
    for attr in dir(executor):
        try:
            value = getattr(executor, attr)
            if isinstance(value, dict):
                logger.info(f"å­—å…¸å±æ€§ '{attr}': åŒ…å« {len(value)} ä¸ªé”®")
                if value:
                    logger.info(f"  å‰å‡ ä¸ªé”®: {list(value.keys())[:3]}")
        except (Exception,):
            pass


# ---------------------------------------------------
# 3. è‡ªåŠ¨æ‰«æ jobs/ ç›®å½•å¹¶è°ƒç”¨ register(executor)
# ---------------------------------------------------
def auto_load_jobs():
    if not os.path.exists(jobs_path):
        logger.warning("jobs ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½")
        return

    # å…ˆæ¸…ç©ºç°æœ‰çš„å¤„ç†å™¨ï¼ˆé¿å…é‡å¤æ³¨å†Œé”™è¯¯ï¼‰
    job_handler = executor.handler
    if hasattr(job_handler, '_handlers') and isinstance(job_handler._handlers, dict):
        job_handler._handlers.clear()
        logger.info(f"å·²æ¸…ç©ºæ‰€æœ‰ä»»åŠ¡å¤„ç†å™¨")

    for filename in os.listdir(jobs_path):
        if filename.endswith(".py") and filename != "__init__.py":
            module_name = filename[:-3]
            module_path = f"{jobs_path}.{module_name}"

            try:
                # ç›´æ¥å¯¼å…¥å¹¶æ³¨å†Œï¼Œä¸å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                module = importlib.import_module(module_path)

                if hasattr(module, "register"):
                    module.register(executor)
                    logger.info(f"åŠ è½½ä»»åŠ¡: {module_path}")
                else:
                    logger.warning(f"{module_path} æœªå®šä¹‰ register(executor)ï¼Œè·³è¿‡")

            except Exception as e:
                logger.error(f"åŠ è½½ä»»åŠ¡ {module_path} å¤±è´¥: {e}")


# ---------------------------------------------------
# 4. ä½¿ç”¨ watchdog åŠ¨æ€ç›‘æ§ç›®å½•å˜åŒ–å¹¶é‡æ–°åŠ è½½ä»»åŠ¡
# ---------------------------------------------------
class DebouncedJobFileEventHandler(FileSystemEventHandler):
    def __init__(self, delay=2.0):  # 2ç§’é˜²æŠ–
        self.delay = delay
        self._timer = None
        self._lock = Lock()
        self._pending_events = set()
        logger.info(f"[watchdog] é˜²æŠ–äº‹ä»¶å¤„ç†å™¨å·²åˆå§‹åŒ–ï¼Œé˜²æŠ–æ—¶é—´: {delay}ç§’")

    def on_any_event(self, event):
        """ç›‘æ§æ‰€æœ‰äº‹ä»¶ï¼Œç”¨äºè°ƒè¯•"""
        if not event.is_directory:
            logger.info(f"[watchdog] æ•è·äº‹ä»¶: {event.event_type} - {event.src_path}")

    def _process_events(self):
        logger.info(f"[watchdog] å¼€å§‹å¤„ç†ç§¯å‹çš„äº‹ä»¶")
        with self._lock:
            events = self._pending_events.copy()
            self._pending_events.clear()
            self._timer = None

        logger.info(f"[watchdog] éœ€è¦å¤„ç† {len(events)} ä¸ªäº‹ä»¶")
        for event_path in events:
            self._handle_single_event(event_path)

    @staticmethod
    def _handle_single_event(event_path):
        logger.info(f"[watchdog] å¤„ç†å•ä¸ªäº‹ä»¶: {event_path}")
        if event_path.endswith(".py") and not event_path.endswith("__init__.py"):
            if os.path.exists(event_path):
                logger.info(f"[watchdog] é‡æ–°åŠ è½½æ¨¡å—: {event_path}")
                module_name = os.path.basename(event_path)[:-3]
                module_path = f"{jobs_path}.{module_name}"

                # å¸è½½æ¨¡å—
                if module_path in sys.modules:
                    del sys.modules[module_path]
                    logger.info(f"[watchdog] å·²å¸è½½æ¨¡å—: {module_path}")

                # é‡æ–°åŠ è½½
                try:
                    load_job_module(module_path)
                except Exception as e:
                    logger.warning(f"[watchdog] é‡æ–°åŠ è½½å¤±è´¥: {e}")
            else:
                logger.error(f"[watchdog] æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {event_path}")

    def _schedule_processing(self, event_path):
        logger.info(f"[watchdog] è°ƒåº¦å¤„ç†: {event_path}")
        with self._lock:
            self._pending_events.add(event_path)

            if self._timer is not None:
                self._timer.cancel()
                logger.info(f"[watchdog] å–æ¶ˆä¹‹å‰çš„å®šæ—¶å™¨")

            self._timer = Timer(self.delay, self._process_events)
            self._timer.start()
            logger.info(f"[watchdog] æ–°å®šæ—¶å™¨å·²å¯åŠ¨ï¼Œå°†åœ¨ {self.delay} ç§’åå¤„ç†")

    def on_modified(self, event):
        logger.info(f"[watchdog] æ–‡ä»¶ä¿®æ”¹äº‹ä»¶: {event.src_path}")
        if not event.is_directory and event.src_path.endswith(".py") and not event.src_path.endswith("__init__.py"):
            logger.info(f"[watchdog] æ£€æµ‹åˆ°Pythonæ–‡ä»¶ä¿®æ”¹: {event.src_path}")
            self._schedule_processing(event.src_path)

    def on_created(self, event):
        logger.info(f"[watchdog] æ–‡ä»¶åˆ›å»ºäº‹ä»¶: {event.src_path}")
        if not event.is_directory and event.src_path.endswith(".py") and not event.src_path.endswith("__init__.py"):
            logger.info(f"[watchdog] æ£€æµ‹åˆ°æ–°Pythonæ–‡ä»¶: {event.src_path}")
            self._schedule_processing(event.src_path)

    def on_deleted(self, event):
        if not event.is_directory:
            logger.info(f"[watchdog] æ–‡ä»¶å·²åˆ é™¤: {event.src_path}")
            module_name = os.path.basename(event.src_path)[:-3]
            module_path = f"jobs.{module_name}"

            if module_path in sys.modules:
                del sys.modules[module_path]
                logger.info(f"[watchdog] æ¨¡å— {module_name} å·²å¸è½½")


def start_job_watchdog():
    logger.info(f"[watchdog] åˆå§‹åŒ–æ–‡ä»¶ç›‘æ§...")

    # æ£€æŸ¥ç›‘æ§ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(jobs_path):
        logger.warning(f"[watchdog] è­¦å‘Š: ç›‘æ§ç›®å½• {jobs_path} ä¸å­˜åœ¨!")
        return

    logger.info(f"[watchdog] ç›‘æ§ç›®å½•: {os.path.abspath(jobs_path)}")

    event_handler = DebouncedJobFileEventHandler(delay=3.0)  # 3ç§’é˜²æŠ–
    observer = Observer()

    try:
        observer.schedule(event_handler, jobs_path, recursive=False)
        observer.start()
        logger.info(f"[watchdog] å¼€å§‹ç›‘æ§ {jobs_path} ç›®å½•å˜åŒ–...")

        # æŒç»­è¿è¡Œç›‘æ§
        while observer.is_alive():
            sleep(1)

    except Exception as e:
        logger.error(f"[watchdog] ç›‘æ§å¼‚å¸¸: {e}")
    finally:
        logger.error("[watchdog] åœæ­¢æ–‡ä»¶ç›‘æ§...")
        observer.stop()
        observer.join()


def watchdog_health_check():
    while True:
        if not watchdog_thread.is_alive():
            logger.error("Watchdog çº¿ç¨‹å·²ç»ˆæ­¢ï¼")
        sleep(10)


# ---------------------------------------------------
# 5. å¯åŠ¨ Pyxxl æ‰§è¡Œå™¨å¹¶å¯åŠ¨ç›‘æ§
# ---------------------------------------------------
if __name__ == "__main__":
    # for logger_name in logging.root.manager.loggerDict:
    #     logger = logging.getLogger(logger_name)
    #     for handler in logger.handlers:
    #         handler.setFormatter(xxl_log_common.TASK_FORMATTER)
    #
    # é¦–å…ˆåŠ è½½ä¸€æ¬¡ä»»åŠ¡
    logger.info("æ‰«æå¹¶åŠ è½½ jobs ç›®å½•ä¸­çš„ä»»åŠ¡...")
    auto_load_jobs()

    # å¯åŠ¨ watchdog ç›‘æ§æ–‡ä»¶å˜åŒ–çš„çº¿ç¨‹
    # start_job_watchdog()
    # å¯åŠ¨ watchdogï¼ˆéå®ˆæŠ¤çº¿ç¨‹ï¼‰
    watchdog_thread = threading.Thread(
        target=start_job_watchdog,
        name="watchdog-monitor",
        daemon=False  # å¿…é¡»è®¾ä¸ºéå®ˆæŠ¤çº¿ç¨‹ï¼
    )
    watchdog_thread.start()
    logger.info("æ–‡ä»¶ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")

    # å¯åŠ¨æ‰§è¡Œå™¨
    logger.info("å¯åŠ¨ XXL-JOB Python æ‰§è¡Œå™¨...")
    try:
        executor.run_executor()

        # åœ¨ä¸»çº¿ç¨‹å¯åŠ¨å
        health_check_thread = threading.Thread(
            target=watchdog_health_check,
            daemon=True
        )
        health_check_thread.start()
    except KeyboardInterrupt:
        logger.error("æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
    except Exception as e:
        logger.error(f"æ‰§è¡Œå™¨å¼‚å¸¸: {e}")
    finally:
        logger.error("æ‰§è¡Œå™¨å·²å…³é—­")
